# Image Captioning Project

This project explores the application of deep learning techniques to automatically generate descriptive captions for images. Using a combination of Convolutional Neural Networks (CNNs) for image feature extraction and Recurrent Neural Networks (RNNs) for text generation, this model creates meaningful captions that describe the content of images.

## Project Overview

The goal of this project is to build a model that can look at an image and generate an appropriate text description. This task combines computer vision and natural language processing, making it an interesting challenge that requires the integration of CNNs and RNNs.

## Dataset

The dataset used for this project contains images with corresponding captions and includes

**Flickr8k and Flickr30k**: Datasets with diverse images and descriptive captions.

## Technologies Used

- **Frameworks**: TensorFlow, Keras
- **Languages**: Python
- **Pretrained Models**: InceptionV3, ResNet

## Acknowledgments

This project was completed as part of my coursework with **Edvancer Eduventures**, where I received guidance on applying deep learning models to real-world tasks.
